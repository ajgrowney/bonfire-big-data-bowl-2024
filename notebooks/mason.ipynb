{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to predict direction and pass/run of the play based on pre-snap information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataview libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = pd.read_csv(DATA_ROOT + 'plays.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playDescriptionToDirection(play_description):\n",
    "    play = re.search('(pass (?:short|deep) (?:left|middle|right))|((?:left|right) (?:guard|tackle|end))|(up the middle)', play_description)\n",
    "    return play.group(0) if play else 'FUMBLED BALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays['playDirection'] = plays['playDescription'].map(playDescriptionToDirection)\n",
    "plays['overTenYards'] = plays['yardsToGo'] > 10\n",
    "\n",
    "numeric_feature_names = ['yardsToGo', 'defendersInTheBox', 'absoluteYardlineNumber']\n",
    "categoric_feature_names = ['offenseFormation', 'down']\n",
    "binary_feature_names = ['overTenYards']\n",
    "target_name = 'playDirection'\n",
    "\n",
    "df = plays[numeric_feature_names + categoric_feature_names + binary_feature_names + [target_name]].copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove fumbled ball as it only occurs 6 times.\n",
    "fumble_mask = df['playDirection'] == 'FUMBLED BALL'\n",
    "df = df[~fumble_mask]\n",
    "\n",
    "first_downs = df[(df['down'] == 1)]\n",
    "df = df[~(df['down'] == 1)]\n",
    "\n",
    "# Undersample to balance the data.\n",
    "# df_group = df.groupby(target_name)\n",
    "# df_balanced = df_group.apply(lambda x: x.sample(df_group.size().min()).reset_index(drop=True))\n",
    "# df = df_balanced\n",
    "\n",
    "# One-hot encode categoric features.\n",
    "df = pd.get_dummies(df, columns=categoric_feature_names)\n",
    "\n",
    "# Shuffle the data.\n",
    "df = df.iloc[np.random.permutation(len(df))].reset_index(drop=True)\n",
    "\n",
    "target = df.pop(target_name)\n",
    "target_raw = target.copy()\n",
    "target = pd.get_dummies(target)\n",
    "\n",
    "input_dim = len(df.columns)\n",
    "output_dim = len(target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets.\n",
    "x, x_val = df[:int(len(df) * 0.8)], df[int(len(df) * 0.8):]\n",
    "y, y_val = target[:int(len(target) * 0.8)], target[int(len(target) * 0.8):]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "x_train = np.asarray(x_train).astype('float32')\n",
    "x_test = np.asarray(x_test).astype('float32')\n",
    "x_val = np.asarray(x_val).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Neural Net Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 3s 163ms/step - loss: 2.4003 - accuracy: 0.0582\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 52ms/step - loss: 1.6119 - accuracy: 0.0719\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.0585 - accuracy: 0.0839\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.9543 - accuracy: 0.0685\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8023 - accuracy: 0.0942\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.8370 - accuracy: 0.0776\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "layer_count = 5\n",
    "\n",
    "def make_sequential_net(layers, epochs, batch_size, learning_rate):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Input(shape=(input_dim,)))\n",
    "  for i in range(layer_count):\n",
    "      # Use input_size * (2/3) + output_size for hidden layer size.\n",
    "      model.add(tf.keras.layers.Dense(input_dim*(2/3)+output_dim, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n",
    "\n",
    "  opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate, decay=1e-5)\n",
    "\n",
    "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "  loss, acc = model.evaluate(x_val, y_val)\n",
    "  return model, acc\n",
    "\n",
    "model, acc = make_sequential_net(layer_count, epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22092103797750307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "depth = 10\n",
    "leaf = 20\n",
    "clf = DecisionTreeClassifier(max_depth=depth, max_leaf_nodes=leaf)\n",
    "score = np.mean(cross_val_score(clf, df, target_raw, cv=10))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Random Forest Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22853510041949737\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=70, max_leaf_nodes=20)\n",
    "score = np.mean(cross_val_score(clf, df, target_raw, cv=10))\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
