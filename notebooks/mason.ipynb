{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to predict direction and pass/run of the play based on pre-snap information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataview libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = pd.read_csv(DATA_ROOT + 'plays.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playDescriptionToDirection(play_description):\n",
    "    play = re.search('(pass (?:short|deep) (?:left|middle|right))|((?:left|right) (?:guard|tackle|end))|(up the middle)', play_description)\n",
    "    return play.group(0) if play else 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays['playDirection'] = plays['playDescription'].map(playDescriptionToDirection)\n",
    "plays['overTenYards'] = plays['yardsToGo'] > 10\n",
    "\n",
    "numeric_feature_names = ['yardsToGo', 'defendersInTheBox', 'absoluteYardlineNumber']\n",
    "categoric_feature_names = ['offenseFormation', 'down']\n",
    "binary_feature_names = ['overTenYards']\n",
    "target_name = 'playDirection'\n",
    "\n",
    "df = plays[numeric_feature_names + categoric_feature_names + binary_feature_names + [target_name]].copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove fumbled ball as it only occurs 6 times.\n",
    "fumble_mask = df['playDirection'] == 'UNKNOWN'\n",
    "df = df[~fumble_mask]\n",
    "\n",
    "first_downs = df[(df['down'] == 1)]\n",
    "df = df[~(df['down'] == 1)]\n",
    "\n",
    "# Undersample to balance the data.\n",
    "# df_group = df.groupby(target_name)\n",
    "# df_balanced = df_group.apply(lambda x: x.sample(df_group.size().min()).reset_index(drop=True))\n",
    "# df = df_balanced\n",
    "\n",
    "# One-hot encode categoric features.\n",
    "df = pd.get_dummies(df, columns=categoric_feature_names)\n",
    "\n",
    "# Shuffle the data.\n",
    "df = df.iloc[np.random.permutation(len(df))].reset_index(drop=True)\n",
    "\n",
    "target = df.pop(target_name)\n",
    "target_raw = target.copy()\n",
    "target = pd.get_dummies(target)\n",
    "\n",
    "input_dim = len(df.columns)\n",
    "output_dim = len(target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets.\n",
    "x, x_val = df[:int(len(df) * 0.8)], df[int(len(df) * 0.8):]\n",
    "y, y_val = target[:int(len(target) * 0.8)], target[int(len(target) * 0.8):]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "x_train = np.asarray(x_train).astype('float32')\n",
    "x_test = np.asarray(x_test).astype('float32')\n",
    "x_val = np.asarray(x_val).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Neural Net Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 3s 26ms/step - loss: 1.2102 - accuracy: 0.1082\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.6478 - accuracy: 0.1307\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.1304\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3215 - accuracy: 0.1520\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.1486\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.1224\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.1386\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.1477\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3212 - accuracy: 0.1486\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3203 - accuracy: 0.1494\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.1491\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3103 - accuracy: 0.1423\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.1472\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.1332\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3076 - accuracy: 0.1443\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.1571\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.3134 - accuracy: 0.1415\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.5082 - accuracy: 0.1392\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 2.1084 - accuracy: 0.1244\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 2.6598 - accuracy: 0.1241\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 3.9137 - accuracy: 0.1887\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "layer_count = 5\n",
    "\n",
    "def make_sequential_net(layers, epochs, batch_size, learning_rate):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Input(shape=(input_dim,)))\n",
    "  for i in range(layer_count):\n",
    "      # Use input_size * (2/3) + output_size for hidden layer size.\n",
    "      model.add(tf.keras.layers.Dense(input_dim*(2/3)+output_dim, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n",
    "\n",
    "  opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate, decay=1e-5)\n",
    "\n",
    "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "  loss, acc = model.evaluate(x_val, y_val)\n",
    "  return model, acc\n",
    "\n",
    "model, acc = make_sequential_net(layer_count, epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22640281026097933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "depth = 10\n",
    "leaf = 20\n",
    "clf = DecisionTreeClassifier(max_depth=depth, max_leaf_nodes=leaf)\n",
    "score = np.mean(cross_val_score(clf, df, target_raw, cv=10))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Random Forest Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23218528418160894\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=70, max_leaf_nodes=20)\n",
    "score = np.mean(cross_val_score(clf, df, target_raw, cv=10))\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
